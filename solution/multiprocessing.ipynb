{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba731531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "\n",
    "def f(q):\n",
    "    y = q.get()\n",
    "    y[0] = 1000\n",
    "\n",
    "\n",
    "def g(q):\n",
    "    x = torch.zeros(1).cuda()\n",
    "    x.share_memory_()\n",
    "    q.put(x)\n",
    "    q.put(x)\n",
    "    while True:\n",
    "        time.sleep(1)  # this process must live as long as x is in use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c673a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = 1000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_32299/1644485645.py\", line 18, in g\n",
      "    time.sleep(1)  # this process must live as long as x is in use\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "queue = mp.Queue()\n",
    "pf = mp.Process(target=f, args=(queue,), daemon=True)\n",
    "pf.start()\n",
    "pg = mp.Process(target=g, args=(queue,), daemon=True)\n",
    "pg.start()\n",
    "pf.join()\n",
    "x = queue.get()\n",
    "print(\"x =\", x.item())  # Prints x = 1000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d997ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "queue.put(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96dc888a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queue.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44093f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f908f5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_queue = mp.Queue()\n",
    "response_queue = mp.Queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea6b451",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76c5fdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "\n",
    "def put_text_into_q(queue, event, psend_pipe, wait_time=0.05):\n",
    "    \"\"\"\n",
    "    Reader process, if queue is not full it will read an `ext` image from\n",
    "    `images_path` and put it onto the `queue` after applying the `transform`, \n",
    "    else it will wait for `wait_time` for the  queue to free up.\n",
    "    \n",
    "    It uses `send_pipe` to signal downstream processes when all images have \n",
    "    been entered into the queue.\n",
    "\n",
    "    It uses `psend_pipe` for indication.\n",
    "    \"\"\"\n",
    "    test_text = \"This is how true happiness looks like 👍😜\"\n",
    "    \n",
    "    queue.put(test_text)\n",
    "    psend_pipe.send((1, \"test text benn sent\"))\n",
    "    \n",
    "    event.set()\n",
    "    queue.join()\n",
    "    \n",
    "    \n",
    "def process_func(queue, out_queue, event, model, device, model_id):\n",
    "    \"\"\"\n",
    "    Detector process, Reads a transformed image from the `queue`\n",
    "    passes it to the detector from `get_detector` and processes the \n",
    "    output using `lock`  and `output_path` file for handling the output.\n",
    "    Uses `pipe` to know if all the images have been written to\n",
    "    the `queue`.\n",
    "    \"\"\"\n",
    "    model.eval().to(device)\n",
    "    while not (event.is_set() and queue.empty()):\n",
    "        try:\n",
    "            text = queue.get(block=True, timeout=0.1)\n",
    "        except Empty:\n",
    "            continue\n",
    "\n",
    "        out = model(text)\n",
    "        out_queue.put(out)\n",
    "        \n",
    "        if model_id == 4:\n",
    "            queue.task_done()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f635150b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def caller(device, models):\n",
    "    start = time.time()\n",
    "    # Initialize sync structures\n",
    "    queue = mp.JoinableQueue()\n",
    "    out_queue = mp.JoinableQueue()\n",
    "    \n",
    "    event = mp.Event()\n",
    "    precv_pipe, psend_pipe = mp.Pipe(duplex=False)\n",
    "    closables = [queue, precv_pipe, psend_pipe]\n",
    "    lock = mp.Lock()\n",
    "\n",
    "    # Initialize processes\n",
    "    put_process = mp.Process(\n",
    "        target=put_text_into_q,\n",
    "        args=(queue, event, psend_pipe)\n",
    "    )\n",
    "    classification_processes = [\n",
    "            mp.Process(\n",
    "                target=process_func,\n",
    "                args=(queue, out_queue, event, models[i], device, i))\n",
    "            for i in range(len(models))]\n",
    "\n",
    "    # Starting processes\n",
    "    put_process.start()\n",
    "    [cp.start() for cp in classification_processes]\n",
    "\n",
    "#     print_qsize(event, precv_pipe, queue)\n",
    "\n",
    "    # Waiting for processes to complete\n",
    "    [cp.join() for cp in classification_processes]\n",
    "    put_process.join()\n",
    "\n",
    "    # Closing everything\n",
    "    [c.close() for c in closables]\n",
    "    print(f\"time taken : {time.time() - start} s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "850dde66",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.set_start_method(\"spawn\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cffd304",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/transformers/src/transformers/modeling_utils.py:429: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  with safe_open(checkpoint_file, framework=\"pt\") as f:\n",
      "/usr/local/lib/python3.8/dist-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "/usr/local/lib/python3.8/dist-packages/torch/storage.py:899: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = cls(wrap_storage=untyped_storage)\n",
      "/usr/local/lib/python3.8/dist-packages/safetensors/torch.py:99: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  with safe_open(filename, framework=\"pt\", device=device) as f:\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from configs.config import AppConfig, ModelConfig\n",
    "\n",
    "from infrastructure.models import TransformerTextClassificationModel\n",
    "\n",
    "\n",
    "def build_models(model_configs: List[ModelConfig]) -> List[TransformerTextClassificationModel]:\n",
    "    models = [\n",
    "            TransformerTextClassificationModel(conf.model, conf.model_path, conf.tokenizer)\n",
    "            for conf in model_configs\n",
    "        ]\n",
    "    return models\n",
    "\n",
    "\n",
    "config = AppConfig.parse_file(\"./configs/app_config.yaml\")\n",
    "models = build_models(config.models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cda7d0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/lib/python3.8/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'put_text_into_q' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/lib/python3.8/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'process_func' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcaller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 25\u001b[0m, in \u001b[0;36mcaller\u001b[0;34m(device, models)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# Starting processes\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     put_process\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m---> 25\u001b[0m     [cp\u001b[38;5;241m.\u001b[39mstart() \u001b[38;5;28;01mfor\u001b[39;00m cp \u001b[38;5;129;01min\u001b[39;00m classification_processes]\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#     print_qsize(event, precv_pipe, queue)\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m# Waiting for processes to complete\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     [cp\u001b[38;5;241m.\u001b[39mjoin() \u001b[38;5;28;01mfor\u001b[39;00m cp \u001b[38;5;129;01min\u001b[39;00m classification_processes]\n",
      "Cell \u001b[0;32mIn[15], line 25\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# Starting processes\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     put_process\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m---> 25\u001b[0m     [\u001b[43mcp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m cp \u001b[38;5;129;01min\u001b[39;00m classification_processes]\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#     print_qsize(event, precv_pipe, queue)\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m# Waiting for processes to complete\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     [cp\u001b[38;5;241m.\u001b[39mjoin() \u001b[38;5;28;01mfor\u001b[39;00m cp \u001b[38;5;129;01min\u001b[39;00m classification_processes]\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/context.py:284\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_posix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/popen_spawn_posix.py:62\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msentinel \u001b[38;5;241m=\u001b[39m parent_r\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(parent_w, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m, closefd\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 62\u001b[0m         \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetbuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     fds_to_close \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "caller(device, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8439b209",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
